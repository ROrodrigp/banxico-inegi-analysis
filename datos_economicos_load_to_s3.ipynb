{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definimos las constantes\n",
    "BUCKET_NAME = \"itam-analytics-ragp\"\n",
    "S3_RAW_DIRECTORY = \"raw/\"\n",
    "PROFILE_NAME = \"datascientist\"\n",
    "LOCAL_DATA_DIR = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para cargar los archivos CSV\n",
    "def cargar_datos_locales():\n",
    "    \"\"\"\n",
    "    Carga los archivos CSV con datos econ√≥micos desde el directorio local.\n",
    "    \"\"\"\n",
    "    datos = {}\n",
    "    \n",
    "    # Buscamos los archivos CSV en el directorio local\n",
    "    csv_files = {\n",
    "        'tipo_cambio': 'tipo_cambio.csv',\n",
    "        'inflacion': 'inflacion.csv',\n",
    "        'tasas_interes': 'tasas_interes.csv'\n",
    "    }\n",
    "    \n",
    "    for nombre, archivo in csv_files.items():\n",
    "        ruta_completa = os.path.join(LOCAL_DATA_DIR, archivo)\n",
    "        \n",
    "        if os.path.exists(ruta_completa):\n",
    "            try:\n",
    "                datos[nombre] = pd.read_csv(ruta_completa)\n",
    "                print(f\"‚úÖ Archivo {archivo} cargado: {len(datos[nombre])} registros\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error al cargar {archivo}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"‚ùå No se encontr√≥ el archivo {ruta_completa}\")\n",
    "    \n",
    "    return datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para conectar a S3\n",
    "def conectar_s3():\n",
    "    \"\"\"\n",
    "    Establece conexi√≥n con AWS S3 usando el perfil especificado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Creamos una sesi√≥n usando el perfil\n",
    "        session = boto3.Session(profile_name=PROFILE_NAME)\n",
    "        # Creamos el cliente S3\n",
    "        s3_client = session.client('s3')\n",
    "        \n",
    "        # Verificamos que el bucket existe\n",
    "        response = s3_client.list_buckets()\n",
    "        buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "        \n",
    "        if BUCKET_NAME in buckets:\n",
    "            print(f\"‚úÖ Conexi√≥n establecida con S3. Bucket '{BUCKET_NAME}' encontrado.\")\n",
    "            return s3_client\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è El bucket '{BUCKET_NAME}' no existe. Verifica el nombre.\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al conectar con S3: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para verificar si un archivo existe en S3\n",
    "def archivo_existe_en_s3(s3_client, s3_key):\n",
    "    \"\"\"\n",
    "    Verifica si un archivo ya existe en S3.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s3_client.head_object(Bucket=BUCKET_NAME, Key=s3_key)\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        # Si obtenemos un error 404, el archivo no existe\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            return False\n",
    "        else:\n",
    "            # Otro tipo de error\n",
    "            print(f\"‚ùå Error al verificar archivo en S3: {str(e)}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para subir los datos a S3\n",
    "def subir_datos_a_s3(datos, s3_client):\n",
    "    \"\"\"\n",
    "    Sube los DataFrames al bucket de S3 en el directorio raw,\n",
    "    verificando primero si los archivos ya existen.\n",
    "    \"\"\"\n",
    "    if not s3_client:\n",
    "        print(\"‚ùå No se puede subir a S3 sin una conexi√≥n v√°lida.\")\n",
    "        return False\n",
    "    \n",
    "    archivos_subidos = 0\n",
    "    archivos_existentes = 0\n",
    "    \n",
    "    for nombre, df in datos.items():\n",
    "        try:\n",
    "            # Generamos la ruta en S3 (sin timestamp)\n",
    "            s3_key = f\"{S3_RAW_DIRECTORY}{nombre}/{nombre}.csv\"\n",
    "            \n",
    "            # Verificamos si el archivo ya existe\n",
    "            if archivo_existe_en_s3(s3_client, s3_key):\n",
    "                print(f\"‚è© Archivo ya existe en s3://{BUCKET_NAME}/{s3_key} - Omitiendo\")\n",
    "                archivos_existentes += 1\n",
    "                continue\n",
    "            \n",
    "            # Si el archivo no existe, lo subimos\n",
    "            csv_buffer = df.to_csv(index=False).encode()\n",
    "            \n",
    "            # Subimos el archivo\n",
    "            s3_client.put_object(\n",
    "                Bucket=BUCKET_NAME,\n",
    "                Key=s3_key,\n",
    "                Body=csv_buffer,\n",
    "                ContentType='text/csv'\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Archivo subido a s3://{BUCKET_NAME}/{s3_key}\")\n",
    "            archivos_subidos += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error al subir {nombre}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nüì§ Proceso completado:\")\n",
    "    print(f\"   - {archivos_subidos} archivos nuevos subidos\")\n",
    "    print(f\"   - {archivos_existentes} archivos ya existentes (omitidos)\")\n",
    "    print(f\"   - {len(datos) - archivos_subidos - archivos_existentes} errores\")\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Iniciando proceso de carga de datos econ√≥micos a S3 - 2025-03-14 16:47:51\n",
      "‚úÖ Archivo tipo_cambio.csv cargado: 240 registros\n",
      "‚úÖ Archivo inflacion.csv cargado: 241 registros\n",
      "‚úÖ Archivo tasas_interes.csv cargado: 240 registros\n"
     ]
    }
   ],
   "source": [
    "print(f\"üîÑ Iniciando proceso de carga de datos econ√≥micos a S3 - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "datos = cargar_datos_locales()\n",
    "if not datos:\n",
    "    print(\"‚ùå No se pudieron cargar datos. Abortando proceso ETL.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì§ FASE DE CARGA\n",
      "---------------\n",
      "‚úÖ Conexi√≥n establecida con S3. Bucket 'itam-analytics-ragp' encontrado.\n",
      "‚úÖ Archivo subido a s3://itam-analytics-ragp/raw/tipo_cambio/tipo_cambio.csv\n",
      "‚úÖ Archivo subido a s3://itam-analytics-ragp/raw/inflacion/inflacion.csv\n",
      "‚úÖ Archivo subido a s3://itam-analytics-ragp/raw/tasas_interes/tasas_interes.csv\n",
      "\n",
      "üì§ Proceso completado:\n",
      "   - 3 archivos nuevos subidos\n",
      "   - 0 archivos ya existentes (omitidos)\n",
      "   - 0 errores\n",
      "\n",
      "‚úÖ PROCESO ETL COMPLETADO EXITOSAMENTE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nüì§ FASE DE CARGA\")\n",
    "print(\"---------------\")\n",
    "s3_client = conectar_s3()\n",
    "exito = subir_datos_a_s3(datos, s3_client)\n",
    "\n",
    "# Resumen final\n",
    "if exito:\n",
    "    print(\"\\n‚úÖ PROCESO ETL COMPLETADO EXITOSAMENTE\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è PROCESO ETL COMPLETADO CON ERRORES\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analisis-economico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
